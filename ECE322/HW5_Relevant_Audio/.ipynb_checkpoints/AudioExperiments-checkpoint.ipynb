{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio is a fun source of data for practicing signal processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of how to play a sound from a vector you generated in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example from https://ipython.org/ipython-doc/3/api/generated/IPython.display.html\n",
    "import numpy as np\n",
    "framerate =44100\n",
    "t=np.linspace(0,5,framerate*5)\n",
    "data = np.sin(2*np.pi*220*t)+np.sin(2*np.pi*224*t)\n",
    "#                                    \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(t,data)\n",
    "plt.title ('wubwubwub')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "#from ipywidgets import Audio\n",
    "Audio(data,rate=framerate) #Show a slider to play the sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More interesting example where you make a keyboard playable from your notebook\n",
    "https://ipython-books.github.io/117-creating-a-sound-synthesizer-in-the-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output #Need a few more things\n",
    "#from ipywidgets import widgets \n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define sampling rate and note duration\n",
    "KeyboardRate = 16000.\n",
    "duration = .25\n",
    "t = np.linspace(\n",
    "    0., duration, int(KeyboardRate * duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function that will make a sine wave of a given frequency f\n",
    "def synth(f):\n",
    "    x = np.sin(f * 2. * np.pi * t)\n",
    "    display(Audio(x, rate=KeyboardRate, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synth(440) #Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define some frequencies\n",
    "notes = 'C,C#,D,D#,E,F,F#,G,G#,A,A#,B,C'.split(',')\n",
    "freqs = 440. * 2**(np.arange(3, 3 + len(notes)) / 12.)\n",
    "notes = list(zip(notes, freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipywebrtc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1a54125eb895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipywebrtc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioRecorder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCameraStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#if this does not work, go to Anaconda Prompt (from Windows Menu in Anaconda folder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#At the prompt, type: conda install -c conda-forge ipywebrtc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#This will download and install the ipywebrtc code that communicates between ipython \"widgets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#and your browser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywebrtc'"
     ]
    }
   ],
   "source": [
    "from ipywebrtc import AudioRecorder,CameraStream\n",
    "#if this does not work, go to Anaconda Prompt (from Windows Menu in Anaconda folder)\n",
    "#At the prompt, type: conda install -c conda-forge ipywebrtc\n",
    "#This will download and install the ipywebrtc code that communicates between ipython \"widgets\"\n",
    "#and your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To record sound from the microphone we need to add some code to Anaconda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We are going to use a CameraStream to get audio from the built-in mic\n",
    "cstream = CameraStream(constraints=\n",
    "                      {'facing_mode': 'user',\n",
    "                       'audio': True,\n",
    "                       'video': False #{ 'width': 640, 'height': 480 } #make True to check video\n",
    "                       })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cstream  #Run this cell to test your camera/mic access. \n",
    "#If you are getting nothing, go to Windows Settings and enable camera and microphone access.\n",
    "#Your browser can be set up to still ask for access permission case-by-case\n",
    "#I made 'video' False above, so if you didn't change it, you should only get audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_recorder = AudioRecorder(filename='sample.wav',stream=cstream)\n",
    "audio_recorder #This should show a record button, download button and playback slider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also bring in sounds from files\n",
    "as vectors to process using Numpy or more specialized signal processing and even voice recognition tools.\n",
    "These sounds could be ones you recorded using the AudioRecorder above, or other available files.\n",
    "To use other sound files, you can use a URL or download them to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(Audio)\n",
    "from scipy.io.wavfile import read\n",
    "rate,song = read(\"CantinaBand3.wav\")  #You can replace with \"sample.wav\" if you recorded and saved a sound sample\n",
    "x=np.array(song,dtype=float)\n",
    "rate,len(x)\n",
    "Audio(song,rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spectrogram of the sample.wav signal - This spectrogram shows the frequency spectrum on y-axis vs time on x-axis\n",
    "#It is available as specgram from matplotlib\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(x); ax1.set_title('Raw audio signal')   \n",
    "ax1.set_xlabel('Sample number')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax2.specgram(x,Fs=rate) #Fs is the sampling frequency, loaded into the 'rate' variable when we read the wav file\n",
    "ax2.set_title('Spectrogram')\n",
    "ax2.set_xlabel('Time(s)')\n",
    "ax2.set_ylabel('Frequency(Hz)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced: do real-time processing on the incoming audio stream (Voice changer etc) http://conference.scipy.org/proceedings/scipy2018/pdfs/mark_wickert_250.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
